[["index.html", "Análisis de datos en psicología II Prólogo", " Análisis de datos en psicología II Manuel Morales Ortiz 2023-09-04 Prólogo Este documento es el resultado de las notas de clase de la asignatura “Diseño y Análisis de datos II” existente en el plan de estudios de graduado en psicología en la Universidad de Sevilla. El enfoque de estos apuntes está dirigido a aquel usuario que no tiene un conocimiento profundo de matemáticas, pero que ha superado un primer curso de análisis de datos donde se hayan estudiado los contenidos relacionados con la estadística descriptiva y los fundamentos de la inferencia estadística. La enseñanza de las materias de análisis de datos suelen ir asociadas al uso de un determinado programa informático que facilite el cálculo de los resultados que de otra manera podrían resultar tediosos. La elección del programa informático debe tener en cuenta la audiencia a la que va dirigido. En el campo de la psicología está muy extendido el uso del programa IBM SPSS (IBM-Corp., 2023), siendo el programa estadístico de referencia en una gran parte de las universidades. Sin embargo, la necesidad de disponer de licencia de pago implica que los futuros usuarios tendrán dificultades para disponer de dicho programa una vez que abandonen la universidad. Para solucionar este problema se suele recurrir a programas de libre distribución como el programa R (R Core Team, 2016). El inconveniente que presenta este programa es su curva de aprendizaje. Dado que el periodo de enseñanza es muy limitado en los planes de estudio, iniciarse en este programa supone una reducción del tiempo disponible para la enseñanza de los contenidos propios de la asignatura. Para solventar este problema hemos recurrido al programa JAMOVI (The Jamovi Team, 2022). Este programa permite aprovechar la flexibilidad y posibilidades de R utilizando un sistema de ventanas más adecuado a las habilidades de los estudiantes de psicología. Este documento se compone de 6 capítulos. En el primero se realiza una introducción a la lógica de la investigación científica. También se realiza un recordatorio de los fundamentos de la inferencia estadística con aplicación de algunas técnicas estadísticas básicas. En los capítulos 2 a 5 se presenta la técnica de ANOVA para estudiar relaciones entre variables (relaciones entre 1 variable independiente y una dependiente en los temas 2 y 3 y relaciones con más de una VI en los temas 4 y 5). En el tema 6 se desarrollan contenidos relacionados con los modelos de regresión lineal. Este trabajo ha sido posible gracias a muchas personas. En primer lugar, a toda la comunidad R por los desarrollos del programa R y en particular a Xie (2023) por el desarrollo de librerías como knitr o bookdown que nos han resultado muy útiles para la redacción de este trabajo. Asimismo, este trabajo se ha visto beneficiado del trabajo de Luque Calvo (2017). Asimismo, a mis alumnos que han sido los mejores revisores del trabajo aquí expuesto. La elaboración de este trabajo se ha realizado bajo las condiciones de la licencia de Creative Commons https://creativecommons.org/share-your-work/public-domain/cc0: Agosto de 2023. "],["introducción-a-los-procedimientos-de-investigación-en-psicología.html", "1 Introducción a los procedimientos de investigación en Psicología", " 1 Introducción a los procedimientos de investigación en Psicología El objetivo de toda investigación psicológica es la obtención de conocimiento válido. Para ello, es necesario que ese conocimiento se haya obtenido mediante un procedimiento sistemático que llamamos método científico. Precisamente, el origen de la Psicología como ciencia se encuentra en la utilización de un método diferente al filosófico para el estudio de la vida mental (Anguera et al., 1995). Aunque hay ocasiones en las que se ha señalado la existencia de distintos métodos de investigación en Psicología, conviene aclarar que compartimos la opinión de que la lógica de la investigación científica configura un único método de investigación, existiendo varias estrategias o procedimientos para alcanzar estos objetivos. Son varios los criterios utilizados para clasificar las distintas estrategias de investigación.(Anguera et al., 1995). Uno de los más relevantes es la existencia de manipulación o no de la variable independiente (VI). Mediante este criterio distinguimos entre los estudios manipulativos y los no manipulativos. Dentro de los manipulativos incluimos los diseños experimentales y los cuasiexperimentales. Entre los no manipulativos distinguimos los selectivos (Ato &amp; Vallejo (2015) los denomina asociativos) de los observacionales. En este tema vamos a estudiar algunos diseños de investigación así como las técnicas estadísticas asociadas a los mismos. Realizaremos una clasificación de los diseños de investigación y posteriormente pasaremos a estudiar los conceptos básicos relacionados con la inferencia estadística. "],["lógica-de-la-investigación-científica.html", "1.1 Lógica de la investigación científica", " 1.1 Lógica de la investigación científica La investigación científica intenta resolver problemas mediante un procedimiento que parte de la formulación de una serie de hipótesis. Con objeto de contrastar dichas hipótesis, el investigador diseña un estudio en el que recogerá información que le permitirá tomar decisiones acerca de la validez de las mismas. La generación de problemas en la investigación científica no obedece a ninguna estrategia sistemática, sino que en muchos casos es el resultado de la casualidad o el azar. Sin embargo, generar problemas relevantes mejora cuando se dispone de un profundo conocimiento de la temática sobre la que se investiga. Aunque la inspiración no tiene reglas, resulta conveniente estar actualizado en el campo de investigación de interés con el que se podrá evaluar la idoneidad y relevancia del problema planteado. El diseño de investigación si tiene una sistemática bien consolidada. Consiste en un plan estructurado de acción que pretende realizar las acciones comparativas (medir la covariación o concomitancia entre dos fenómenos), en condiciones de validez. Aunque existen muchos criterios de clasificación (estrategia, número de variables, grado de intervención, etc.), aquí vamos a centrarnos en el que consideramos más relevante y que se relaciona con el tipo de estrategia seguida por el investigador para realizar las acciones comparativas en base a los objetivos de investigación. Se distinguen dos estrategias: Transversal: Utiliza grupos diferentes para estudiar cada uno de los valores de la variable independiente. Supongamos que queremos conocer qué procedimiento es el mejor para conseguir reducir peso. Tenemos cuatro condiciones (sin tratamiento, dieta, fármacos y dieta + ejercicio). Seleccionamos una muestra de individuos y asignamos aleatoriamente cada uno de ellos a uno de los grupos. A cada individuo se le mide la VD (peso) antes de comenzar el tratamiento y después de recibir el tratamiento. Comparamos la diferencia de peso en cada una de las cuatro condiciones. Longitudinal: Utiliza un único grupo que recibe todos los valores de la variable independiente en momentos distintos. Supongamos que queremos estudiar cómo influye el paso del tiempo en el recuerdo. Para ello, se le pide a los individuos que lean una historia durante 15 minutos. Pasada una hora se les indica que escriban todo lo que recuerdan de la historia. Asimismo, se le vuelve a pedir que escriban todo lo que recuerdan al cabo de un día, una semana y un mes. Por lo general, estas dos estrategias suelen aparecer conjuntamente en muchos diseños de investigación. "],["validez-de-las-investigaciones.html", "1.2 Validez de las investigaciones", " 1.2 Validez de las investigaciones La validez de un estudio depende la naturaleza de las variables y sus definiciones, del diseño de investigación y de la técnica estadística utilizada. 1.2.1 Validez de las variables y definiciones En toda investigación científica se trabaja con conceptos que deben ser operacionalizados para que puedan ser medidos y presenten un significado unívoco. Los problemas de validez surgen cuando las operaciones realizadas no tienen nada que ver con el constructo estudiado o su vinculación es parcial. Las variables pueden medirse mediante cuatro escalas de medida (nominal, ordinal, intervalo y razón). La elección del tipo de medida determinará el tipo de análisis de los datos. Hay ocasiones en las que se han utilizado los términos de cualitativo y cuantitativo para clasificar los distintos tipos de variables (Ato &amp; Vallejo, 2007). Dentro de las variables cualitativas suelen diferenciarse las variables en función de que su escala de medida sea nominal u ordinal. Las variables cuantitativas se distinguen en función de que su dominio sea discreto o continuo. Otra clasificación frecuente en Psicología es la distinción entre variable independiente (VI) o variable predictora (VP), variable dependiente (VD) y variables extrañas (VVEE). En ocasiones se se denomina a la VD variable criterio en los contextos en los que no hay manipulación en el diseño de investigación. En estos estudios a la VD también se le denomina variable de respuesta (VR) y a la VI variable predictora. 1.2.2 Validez del diseño de investigación Con el diseño tenemos que asegurarnos de que las variables extrañas están debidamente controladas (validez interna). Para ello, resulta conveniente utilizar técnicas de control tales como la manipulación de la VI, la aleatorización, el mantenimiento constante de dichas variables o el control estadístico. Asimismo, es importante considerar la generalización de los resultados del estudio a otras situaciones. En este caso, estamos hablando de validez externa. 1.2.3 Validez de conclusión estadística La elección de la técnica estadística también influye en la validez de la investigación. Una técnica mal seleccionada puede llevarnos a sacar conclusiones inadecuadas. Afecta a la determinación de la existencia de covariación entre las variables y a su grado. El procedimiento para obtener conclusiones estadísticas es el contraste de hipótesis. Este procedimiento consiste en la toma de decisiones sobre dos hipótesis rivales y excluyentes en base a la probabilidad calculada de un estadístico. Más adelante se desarrollará este concepto para su completa comprensión. Entre los errores que se cometen mediante la contrastación de hipótesis es el considerar que existe relación cuando no existe (error tipo I o riesgo \\(\\alpha\\)), o considerar que no existe relación cuando la hay (error tipo II o riesgo \\(\\beta\\)). Otro error posible es la sobre-estimación o infra-estimación de la relación. Posibles factores que pueden afectar a la conclusión estadística es la baja potencia y la violación de los supuestos. También es importante considerar la magnitud del efecto y la significación práctica y clínica de los resultados. 1.2.4 Contraste de hipótesis estadísticas Dentro de la inferencia estadística buscamos realizar comparaciones y establecer relaciones mediante la estimación de parámetros y el contraste de hipótesis. El primer procedimiento puede hacerse mediante la estimación puntual o por intervalos. En cambio, el contraste de hipótesis es la toma de decisiones acerca de si un conjunto de datos corrobora una hipótesis. Supone cubrir una serie de etapas: 1) Formulación de las hipótesis: Se plantean la hipótesis nula (\\(H_0\\)) que considera que las variaciones existentes entre las condiciones se debe al azar y la hipótesis alternativa (\\(H_1\\)) que niega la hipótesis nula y considera que las variaciones en una variable están relacionadas con los cambios en la otra. Las hipótesis pueden ser bidireccionales (no conocemos el sentido de la relación como por ejemplo \\(\\mu_1 = \\mu_2\\)) o unidireccionales (el investigador plantea donde se encontrarán las diferencias como por ejemplo \\(\\mu_1 \\leq \\mu_2\\) ). 2) Definición del estadístico de contraste: Su cálculo supone la realización de un estudio empírico en el que se ha extraído una muestra aleatoria de la población. Este estadístico debe tener una distribución de probabilidad conocida. 3) Regla de decisión: Se basa en la compatibilidad que existe entre la hipótesis nula y los datos empíricos (Pardo &amp; San Martin, 2010). Permite determinar la probabilidad de que \\(H_0\\) sea cierta en base a nuestros resultados. Para determinar el grado de apoyo de \\(H_0\\) se divide a la distribución teórica en dos regiones (región de confianza y región crítica). La región de confianza es la zona de la distribución teórica en la que se acepta \\(H_0\\). Existe consenso en considerar que esta región alcance el 95% de probabilidad. La región crítica es la zona complementaria a la región de confianza (por lo que cubre el 5% de la distribución) y si el estadístico pertenece a esa zona se rechaza \\(H_0\\). Si la hipótesis es bilateral la región crítica estará a ambos lados de la distribución teórica. En cambio, si la hipótesis es unilateral la región de confianza estará situada en una de las colas de las distribución. Ejemplo 1.1: A continuación, se presentan los resultados de un estudio en el que se quiso comparar el aprendizaje de los niños dependiendo del tipo de método (fonético versus global). Cada niño sólo fue entrenado con un único método y se quería conocer si había diferencias significativas entre ambos métodos. Nos estamos planteando una hipótesis bidireccional: Tabla 1.1: Datos del ejemplo 1.1 Fonetico 6 6 3 4 2 5 7 Global 4 5 6 7 8 4 8 \\(H_0\\): No hay diferencias entre los métodos de aprendizaje (\\(\\mu_{F} = \\mu_G\\)) \\(H_1\\): El aprendizaje depende del método (\\(\\mu_{F} \\neq \\mu_G\\)) Para contrastar esta hipótesis necesitamos un estadístico con distribución de probabilidad conocida. En este caso, es el estadístico t de Student: \\[ \\bar{Y}_{\\bar{Y}_{1} - \\bar{Y}_{2}}= \\bar{Y}_{1} - \\bar{Y}_{2} \\] \\[ Var(\\bar{Y}_{1} - \\bar{Y}_{2}) = \\sigma_{1}^{2}/n_{1} + \\sigma_{2}^{2}/n_{2} \\] \\[ t = \\frac{\\bar{Y}_{\\bar{Y}_{1} - \\bar{Y}_{2}}}{Var(\\bar{Y}_{1} - \\bar{Y}_{2})} \\sim t(n-2) \\] En nuestro ejemplo, el valor del estadístico t puede obtenerse con el programa R: ## ## Two Sample t-test ## ## data: rendimiento by metodo ## t = -2.5955, df = 12, p-value = 0.02342 ## alternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0 ## 95 percent confidence interval: ## -4.2044435 -0.3669851 ## sample estimates: ## mean in group 1 mean in group 2 ## 4.142857 6.428571 Encontramos que el valor del estadístico t vale -2.596 y su valor de probabilidad es 0.023. En base a estos resultados podemos rechazar \\(H_0\\). Esto significa que el estadístico t se aleja bastante de la predicción establecida mediante la hipótesis nula. Es decir, existe muy poca compatibilidad entre nuestros datos y \\(H_0\\). Para aceptar estos resultados debemos confirmar que se cumplen los supuestos de la prueba (normalidad de las muestras y homogeneidad de las varianzas 1): ## ## Shapiro-Wilk normality test ## ## data: rendimiento[1:7] ## W = 0.92025, p-value = 0.4713 ## ## Shapiro-Wilk normality test ## ## data: rendimiento[8:14] ## W = 0.91511, p-value = 0.4324 Tabla 1.2: Prueba de homogeneidad de varianzas del ejemplo 1.1 Df F value Pr(&gt;F) group 1 0.06 0.8106346 12 NA NA Ejemplo 1.2: A continuación, se presentan los resultados de un estudio en el que se quiso comparar el aprendizaje de los niños dependiendo del tipo de método (fonético versus global). Cada niño sólo fue entrenado con un único método y se esperaba encontrar un mayor rendimiento con el método global. Aquí nos planteamos una hipótesis unidireccional: Tabla 1.1: Datos del ejemplo 1.1 Fonetico 6 6 3 4 2 5 7 Global 4 5 6 7 8 4 8 \\(H_0\\): No hay diferencias en el aprendizaje (\\(\\mu_{F} \\geq \\mu_G\\)) \\(H_1\\): El aprendizaje es mejor con el método global (\\(\\mu_{F} &lt; \\mu_G\\)) Para contrastar esta hipótesis necesitamos un estadístico con distribución de probabilidad conocida. En este caso, el estadístico es el mismo y tiene el mismo valor. Sólo cambia su probabilidad: ## ## Two Sample t-test ## ## data: rendimiento by metodo ## t = -2.5955, df = 12, p-value = 0.01171 ## alternative hypothesis: true difference in means between group 1 and group 2 is less than 0 ## 95 percent confidence interval: ## -Inf -0.7161774 ## sample estimates: ## mean in group 1 mean in group 2 ## 4.142857 6.428571 Ejemplo 1.3: Con los mismos datos del ejemplo anterior supongamos que el investigador está interesado en conocer si la media del rendimiento en la población de los estudiantes es 6. Para ello formula las siguientes hipótesis: \\(H_0\\): \\(\\mu_{rendimiento}\\) = 6 \\(H_1\\): \\(\\mu_{rendimiento} \\neq\\) 6 Como no conocemos el sentido de la dirección asumimos que la hipótesis es bilateral. Para contrastar esta hipótesis necesitamos conocer si la distribución de la variable sigue una ley normal. En caso de que se cumpla esta hipótesis realizaremos el contraste con la prueba t para una muestra. Si no se cumple, usaremos la prueba de Wilcoxon para una muestra. El estadístico de Shapiro-Wilks indica que se cumple la normalidad de la variable por lo que usamos la prueba t. shapiro.test(rendimiento) ## ## Shapiro-Wilk normality test ## ## data: rendimiento ## W = 0.92677, p-value = 0.2747 t.test(rendimiento, mu = 6) ## ## One Sample t-test ## ## data: rendimiento ## t = -1.3512, df = 13, p-value = 0.1997 ## alternative hypothesis: true mean is not equal to 6 ## 95 percent confidence interval: ## 4.143709 6.427720 ## sample estimates: ## mean of x ## 5.285714 Aceptamos la hipótesis de que el valor medio de la variable rendimiento es 6 en la población. Ejemplo 1.4: Supongamos que construimos un examen para evaluar los conocimientos de los estudiantes de Psicología en la materia de Diseño y Análisis de Datos II. El examen tendrá 10 preguntas con 3 opciones de respuesta y solo una correcta. Queremos conocer cuántas preguntas debe responder correctamente el alumno para estar seguros de que domina la materia y de que no ha respondido por azar. Las hipótesis en este contraste estadístico serán: \\(H_0\\): El alumno no sabe por lo que responde al azar (\\(\\pi_{acierto} \\leq\\) 0.333) \\(H_1\\): El alumno sabe. No responde al azar (\\(\\pi_{acierto} &gt;\\) 0.333) Ahora necesitamos determinar cuántas preguntas suponen responder por azar. Está claro si el alumno acierta sólo 1 pregunta la probabilidad de que haya respondido por azar 0 ó 1 es muy alta. En la siguiente figura se aprecia que los valores más probables están comprendidos entre 2 y 4: Figura 1.1: Distribución binomial # Probabilidad igual a 2: dbinom(2,10,1/3) ## [1] 0.1950922 # Probabilidad igual a 3: dbinom(3,10,1/3) ## [1] 0.2601229 # Probabilidad igual a 4: dbinom(4,10,1/3) ## [1] 0.2276076 Por tanto, necesitamos encontrar el número de preguntas acertadas que tengan una probabilidad de ser acertadas por azar \\(\\leq\\) 0,05. Esto se consigue con 6 preguntas acertadas. Con 5 preguntas acertadas estaríamos por encima del nivel de riesgo establecido por convención del 5%: # Probabilidad menor o igual a 6: pbinom(6,10,1/3) [1] 0.9803384 # Probabilidad de la región crítica con 6 preguntas: 1 - pbinom(6,10,1/3) [1] 0.01966164 # Probabilidad de la región crítica con 5 preguntas: 1 - pbinom(5,10,1/3) [1] 0.07656353 No obstante, el criterio de 0,05 es un criterio establecido arbitrariamente y que supone la ausencia de factores contaminantes que estarían actuando en la situación real de examen y que podrían afectar al resultado del examen. Un profesor algo más exigente podría considerar la necesidad de aprobar acertando 7 preguntas. En este caso, la probabilidad de que un estudiante acertara por azar sería: # Probabilidad menor o igual a 7: pbinom(7,10,1/3) [1] 0.996596 # Probabilidad de la región crítica con 7 preguntas: 1 - pbinom(7,10,1/3) [1] 0.003403953 En este caso no es necesario calcular la normalidad de los errores, ya que si las muestras son normales también serán normales los errores. Esto se verá con más claridad en el próximo tema.↩︎ "],["potencia-de-un-contraste.html", "1.3 Potencia de un contraste", " 1.3 Potencia de un contraste Dado que él área de una distribución teórica vale 1 sabemos que 1 - \\(\\alpha\\) es la probabilidad asociada a la región de confianza. O lo que es lo mismo, la probabilidad de aceptar \\(H_0\\) cuando es cierta. Del mismo modo, 1 - \\(\\beta\\) es la probabilidad de rechazar \\(H_0\\) cuando es falsa. A esta probabilidad se le llama potencia de la prueba. Figura 1.2: Errores en la inferencia estadística Pardo &amp; San Martin (2010) consideran que la potencia de un contraste hace referencia “a la sensibilidad del contraste para detectar como falsa una hipótesis nula que realmente lo es. Cuanto mayor es la potencia, mayor es la de que una hipótesis nula falsa sea reconocida como tal. Si la potencia es baja, también será baja la probabilidad de detectar un efecto.” La potencia de la prueba depende del nivel de riesgo \\(\\alpha\\), del error típico de la distribución teórica y del valor real de \\(H_1\\). Puede aumentarse modificando cualquiera de los tres factores mencionados, pero una forma sencilla de aumentarla es incrementando el tamaño de la muestra. Asimismo, mejorar el diseño del estudio o utilizar medidas con mayor fiabilidad y validez también son estrategias posibles para mejorar la potencia estadística del contraste. "],["tamaño-del-efecto.html", "1.4 Tamaño del efecto", " 1.4 Tamaño del efecto Hemos visto anteriormente que para determinar la potencia de la prueba un elemento necesario es fijar el valor real de \\(H_1\\). Como este valor no se conoce a priori debemos determinarlo. Pues bien, la distancia del valor del estadístico entre \\(H_0\\) y el valor real de \\(H_1\\) es lo que se denomina tamaño del efecto. Cuando se realizan comparaciones entre variables el tamaño del efecto hace referencia a la magnitud de la diferencia, mientras que cuando se estudian relaciones el tamaño del efecto se refiere a la intensidad de la relación. Dado que la potencia de un contraste depende del tamaño muestral podemos encontrar diferencias de medias muy pequeñas que sean significativas. Bastará con tener un tamaño de muestra suficientemente grande. Por tanto, la significación estadística permite contrastar hipótesis, pero no es un buen indicador de la relevancia de la relación. Existen una gran variedad de medidas del tamaño del efecto. Pardo &amp; San Martin (2010) consideran que todas ellas pueden clasificarse en dos grandes tipos: 1) basadas en la estandarización de la diferencia entre las medias y 2) las basadas en la proporción de varianza explicada. En los siguientes temas se estudiarán algunos de ellos. "],["contrastes-de-hipótesis-en-los-programas-estadísticos.html", "1.5 Contrastes de hipótesis en los programas estadísticos", " 1.5 Contrastes de hipótesis en los programas estadísticos 1.5.1 Contrastes para 1 variable El árbol de decisión para estos contrastes es el siguiente: Figura 1.3: Contrastes para 1 variable 1.5.1.1 Prueba t para 1 muestra mediante el programa JAMOVI Se selecciona el módulo de “Pruebas T” y marcamos la opción ”Prueba T para una muestra”. En la ventana de la prueba T para una muestra aparece por defecto seleccionada la prueba T y marcando la opción de “Comprobación de supuestos” puede obtenerse el resultado de la prueba de normalidad. Para realizar el análisis es necesario indicar el valor de prueba en la sección de “Hipótesis” (en nuestro ejemplo se ha introducido el valor de 47). Por defecto, aparece marcada la opción del contraste bilateral aunque existen opciones para estudiar los contrastes unilaterales. Asimismo, tendríamos que marcar la opción de “Rangos de Wilcoxon” en el caso de que no se acepte la hipótesis de normalidad. Figura 1.4: Prueba t para una muestra en JAMOVI Figura 1.5: Prueba t para una muestra en JAMOVI 1.5.1.2 Prueba t para 1 muestra en el programa SPSS 1.5.1.2.1 Prueba de normalidad de Shapiro-Wilk Para determinar la normalidad será necesario aplicar la prueba de Shapiro-Wilks. En el programa SPSS se hace marcando Analizar + Explorar + Gráficos + Gráficos con pruebas de normalidad. Los resultados obtenidos pueden observarse en las siguientes imágenes. Figura 1.6: Prueba de normalidad Shapiro-Wilks en el programa SPSS Figura 1.7: Prueba de normalidad en SPSS Figura 1.8: Prueba de normalidad en SPSS Figura 1.9: Resultados de la prueba de normalidad La prueba t para 1 muestra se realiza marcando Analizar + Comparar medias + Prueba T para una muestra: Figura 1.10: Prueba t para una muestra en el programa SPSS Figura 1.11: Prueba t para una muestra en el programa SPSS Será necesario introducir la VD a estudiar en el cuadro de “Variable a contrastar”. El valor del contraste es cero por defecto, pero habrá que introducir el valor de la hipótesis a estudiar. 1.5.1.2.2 Prueba de Wilcoxon para una muestra Necesitamos marcar Analizar + Pruebas no paramétricas + Cuadro de diálogos antiguos + 2 muestras relacionadas. Observamos que el programa SPSS nos pide introducir dos variables, ya que esta prueba está diseñada para estudiar la relación entre dos variables. Sin embargo, puede utilizarse introduciendo la variable en cuestión y como segunda variable una nueva que hemos creado con el valor de contraste de nuestras hipótesis (en la figura aparece con el nombre de Mdn): Figura 1.12: Prueba de Wilcoxon en el SPSS Figura 1.13: Prueba de Wilcoxon en el SPSS 1.5.2 Contrastes para 1 VI cualitativa y una VD cuantitativa El árbol de decisión para los diseños en los que solo hay 1 medida por sujeto (muestras independientes) es: Figura 1.14: Técnicas para dos muestras independientes 1.5.2.1 Prueba t para muestras independientes en JAMOVI Se selecciona la opción de muestras independientes en el modulo de “Pruebas T”. Se introduce la variable dependiente (cuantitativa) en el cuadro de “Variables dependientes” y la variable cualitativa en el cuadro de “Variable de agrupación”. Se seleccionan las opciones para comprobar los supuestos de la prueba y se elige la prueba (T de student, T de Welch o U de Mann-Whitney), dependiendo de los supuestos que se cumplan. Figura 1.15: Prueba t para muestras independientes en JAMOVI 1.5.2.2 Prueba t para muestras independientes en SPSS Se realiza marcando Analizar + Comparar medias + Prueba T para muestras independientes: Figura 1.16: Prueba t para muestras independientes en SPSS Figura 1.17: Prueba t para muestras independientes en SPSS 1.5.2.3 Prueba U de Mann-Whitney para muestras independientes en SPSS Se obtiene marcando Analizar + Pruebas no paramétricas + Cuadro de diálogos antiguos + 2 muestras independientes. Figura 1.18: Prueba U para muestras independientes en SPSS Figura 1.19: Prueba U para muestras independientes en SPSS 1.5.3 Pruebas para muestras relacionadas (2 medidas por unidad de observación) El árbol de decisión para este apartado es el siguiente: Figura 1.20: Pruebas para dos muestras relacionadas La variable sobre la que se realiza el contraste es la diferencia entre las medidas de los dos momentos. Por tanto, el análisis de estos diseños se convierte en el análisis sobre 1 muestra que ya se ha estudiado anteriormente. 1.5.3.1 Prueba t para muestras relacionadas en el programa JAMOVI Se selecciona la opción de “Muestras Apareadas” en el modulo de “Pruebas T”. Se introduce las dos variables dependientes (cuantitativas) en el cuadro de *“Variables Apareadas”. Se selecciona la opción “Comprobación de supuestos” de la prueba y se elige la prueba (T de student o W de Wilcoxon), dependiendo de que se cumpla el supuesto de normalidad. Estos resultados son los mismos que si se hubieran calculado la diferencia entre las dos medidas y se hubiera aplicado la prueba T para una muestra. Figura 1.21: Prueba t para muestras relacionadas en JAMOVI 1.5.3.2 Prueba t para muestras relacionadas en el programa SPSS Se realiza marcando Analizar + Comparar medias + Prueba T para muestras relacionadas: Figura 1.22: Prueba t para muestras relacionadas en SPSS Figura 1.23: Prueba t para muestras relacionadas en SPSS 1.5.3.2.1 Prueba de Wilcoxon para 2 muestras relacionadas Necesitamos marcar Analizar + Pruebas no paramétricas + Cuadro de diálogos antiguos + 2 muestras relacionadas. Figura 1.24: Prueba de Wilcoxon para muestras relacionadas en SPSS Figura 1.25: Prueba de Wilcoxon para muestras relacionadas en SPSS "],["relación-entre-una-variable-cualitativa-y-otra-cuantitativa-i-diseños-transversales.html", "2 Relación entre una variable cualitativa y otra cuantitativa (I): Diseños transversales", " 2 Relación entre una variable cualitativa y otra cuantitativa (I): Diseños transversales El objetivo de este tema es introducir las técnicas de análisis de los diseños que estudian las relaciones entre una variable independiente (VI) cualitativa y una variable dependiente (VD) cuantitativa mediante la comparación de grupos. En el caso más sencillo tendremos un factor (variable cualitativa) con dos valores (niveles o condiciones). Esto se traduce en la creación de dos grupos. A uno de ellos se le denomina grupo control y al otro grupo experimental. Ato &amp; Vallejo (2015) distinguen dos tipos de factores: 1) de tratamiento: son valores que asigna el investigador a los grupos y 2) de clasificación: cuando la administración no está controlada por el investigador (p.ej., el género). En este tipo de estudios se pretende buscar diferencias entre las distintas condiciones (valores de la VI). Establecer estas diferencias puede hacerse de muchas formas. Por ejemplo, en el caso del estudio de la dieta, podemos preguntarnos por el número de individuos que bajaron de peso o por el promedio de pérdida de peso en el grupo. Dependiendo de la medida que utilicemos, las técnicas estadísticas serán distintas. Asimismo, no todas las diferencias van a ser importantes. Por ejemplo, si encontramos que el grupo de dieta mostró una diferencia media de 10 gramos con el grupo que no recibió tratamiento podemos considerar que no es una diferencia relevante. Determinar si una diferencia será significativa o no será misión de la técnica estadística utilizada. Por último, las diferencias que encontremos pueden ser de tipo exploratorio (p. ejemplo, cuando se establecen relaciones de covariación sin pretensión de causalidad al no poder garantizarse la eliminación de explicaciones alternativas mediante el control de VVEE), o de tipo explicativo donde la covariación entre la VI y la VD se ha establecido en un contexto en el que se han utilizado procedimientos de control de VVEE para eliminar hipótesis rivales. En este tipo de diseños pueden utilizarse diversas técnicas de control que van desde el mantenimiento constante de la VE, la eliminación, la equiparación de valores mediante el método de bloqueo y/o el control estadístico. Ato &amp; Vallejo (2015) consideran que la tradición skinneriana basada en estudios de laboratorio con un gran control de las condiciones ambientales usa fundamentalmente la eliminación y el mantenimiento constante como formas de control. Por el contrario, en otras áreas de la Psicología, es más frecuente el uso del control estadístico y, en particular, de la aleatorización dentro del contexto denominado experimento aleatorio. Aplicado a este tipo de diseños el experimento aleatorio en su forma más pura consiste en seleccionar aleatoriamente los valores de la VI y asignar aleatoriamente los participantes a las distintas condiciones del estudio. Con ello, se espera que el azar neutralice cualquier VE presente en el estudio. En otros casos, la aleatorización no será completa y se restringirá en algún modo. "],["criterios-de-selección-de-la-técnica-estadística.html", "2.1 Criterios de selección de la técnica estadística", " 2.1 Criterios de selección de la técnica estadística En la siguiente figura aparece el árbol de decisión para elegir la técnica estadística adecuada cuando el diseño es transversal: Figura 2.1: Clasificación de las técnicas de análisis Como puede observarse en el diagrama son dos criterios los que nos permiten determinar la técnica estadística adecuada. En primer lugar, será necesario determinar si las muestras de los distintos grupos proceden de una distribución normal. Para ello, puede utilizarse la prueba de Shapiro-Wilks. Si no existe evidencia de que las muestras estudiadas procedan de una población normal o que la distribución de los errores es normal se utilizará la técnica de Kruskal-Wallis. En el caso de que haya información suficiente para asumir el supuesto de normalidad será necesario determinar si las varianzas de los grupos son homogéneas o no. Para ello, puede utilizarse la prueba de Levene. En el caso de que no se cumpla este supuesto se utilizará la prueba de Brown-Forsythe 2. Si los datos de nuestro estudio cumplen todos los supuestos utilizaremos la técnica de Anova de 1 factor completamente aleatorizado. Otra posibilidad es utilizar la técnica de Welch.↩︎ "],["anova-de-1-factor-completamente-aleatorizado.html", "2.2 ANOVA de 1 factor completamente aleatorizado", " 2.2 ANOVA de 1 factor completamente aleatorizado Se asume el supuesto de que los distintos grupos representan muestras aleatorias que proceden de poblaciones normales con igual media y varianza y que los errores siguen una distribución normal. La formulación del modelo estadístico es: \\[ Y_{ij} = \\mu_{i} + \\epsilon_i \\] donde \\(Y_{ij}\\) es la variable dependiente para el sujeto i del grupo j y \\(\\mu_{i}\\) es el valor esperado (la media). El último elemento del modelo \\(\\epsilon_{ij}\\) es el llamado error o término residual. Como en todo contraste estadístico, se plantean dos hipótesis, \\(H_0\\) o hipótesis nula y \\(H_1\\), hipótesis alternativa. En este modelo se definen de la siguiente forma: \\(H_{0}\\): \\(\\mu_{1} = \\mu_{2} = \\cdots \\mu_{j}\\) (todas las medias son iguales) \\(H_{1}\\): \\(\\mu_{i} \\neq \\mu_{j}\\) (i \\(\\neq\\) j) (no todas las medias son iguales) El contraste compara las diferencias entre medias muestrales con la variabilidad experimental para decidir si ésta ha podido generar esas diferencias o no. Tanto la diferencia entre las medias (MCA) como la variabilidad experimental (varianza intrasujeto ó MCE) son dos formas de estimar la varianza poblacional. Bajo el supuesto de hipótesis nula, ambas varianzas deben ser iguales. La comparación de ambas varianzas sigue una distribución de probabilidad (distribución F) que permite realizar el contraste estadístico: \\[ F = \\frac{MC_{A}}{MC_{E}} \\sim F(gl_{MC_{A}},gl_{MC_{E}}) \\] Se rechaza \\(H_{0}\\) si el estadístico F cae dentro de la región crítica; en caso contrario, se mantiene. Si se rechaza esta hipótesis se concluye que no todas las medias son iguales. Ejemplo 2.1 : A continuación, se presentan los datos de un estudio en el que se quiso comparar los resultados en una prueba de atención de tres grupos de 5 niños (A = sanos, B = con tumor astrocitoma y C = con tumor meduloblastoma) Tabla 2.1: Datos del ejemplo 2.1 A B C s1 30 16 10 s2 35 5 7 s3 15 22 15 s4 21 23 6 s5 24 22 12 Figura 2.2: Boxplot de los resultados del ejemplo 2.1 Tabla 2.2: Resultados del ejemplo 2.1 Df Sum Sq Mean Sq F value Pr(&gt;F) grupo 2 562.5333 281.26667 6.426504 0.0126711 Residuals 12 525.2000 43.76667 NA NA Los resultados de aplicar el modelo estadístico permiten rechazar la hipótesis nula de que no hay diferencias entre los grupos. Pueden obtenerse los valores de los parámetros que aparecen en el modelo: \\[ Y_{ij} = \\mu_{i} + \\epsilon_i \\] \\(Y_{ij}\\) es cada una de las puntuaciones. Así, por ejemplo, \\(Y_{1A}\\) será el valor del sujeto 1 en el grupo de los sanos \\(Y_{1A}\\) = 30. Asimismo, \\(Y_{1B}\\) será la puntuación del primer sujeto del grupo astrocitoma (\\(Y_{1B}\\) = 16). \\(\\mu_i\\) será la media del grupo. Por tanto, \\(\\mu_1\\) será para el grupo de los individuos sanos 25. Para el grupo astrocitoma será 17.6. Por último, para el grupo meduloblastoma tendremos 10; \\(\\epsilon_{ij}\\) es un valor específico para cada individuo. Es la diferencia entre la puntuación predicha por el modelo y la puntuación obtenida por el individuo. Así, para el sujeto 1 del grupo sano la puntuación predicha será \\(Y_{1Apred}\\) = 25 y su error \\(\\epsilon_{ij}\\) = 30 - 25 = 5. Otra forma de plantear este modelo es descomponiendo la puntuación de los sujetos en dos elementos: 1) la variabilidad explicada por el modelo y 2) la variabilidad no explicada por el modelo (error). De este modo, la predicción del modelo (media del grupo) puede descomponerse en dos elementos (media total + diferencia de la media del grupo con respecto a la media total): \\[ Y_{ij} = \\mu_{..} + (\\mu_j - \\mu_{..}) + \\epsilon_{ij} \\] donde \\(\\mu_{..}\\) es la media de todas las puntuaciones; \\((\\mu_j - \\mu_{..})\\) es la diferencia de la media del grupo y la media total y \\(\\epsilon_{ij}\\) es el error. En el caso de la primera puntuación del grupo sano sería: 30 = 17.5333333 + 7.4666667+ 5 "],["comprobación-de-los-supuestos.html", "2.3 Comprobación de los supuestos", " 2.3 Comprobación de los supuestos Es necesario determinar si las muestras son independientes. Esto se asume siempre y cuando hayan sido extraídas al azar 3. Asimismo, se necesita determinar si las muestras proceden de una población normal con la misma varianza. También tendremos que comprobar que la distribución de los errores sigue una ley normal. Prueba de normalidad para cada uno de los grupos: Grupo 1: ## ## Shapiro-Wilk normality test ## ## data: aciertos[1:5] ## W = 0.98829, p-value = 0.9734 Grupo 2: ## ## Shapiro-Wilk normality test ## ## data: aciertos[6:10] ## W = 0.78479, p-value = 0.06056 Grupo 3: ## ## Shapiro-Wilk normality test ## ## data: aciertos[11:15] ## W = 0.95695, p-value = 0.7866 Prueba de homogeneidad de varianzas: Tabla 2.3: Prueba de Levene del ejemplo 2.1 Df F value Pr(&gt;F) group 2 0.4599212 0.6420136 12 NA NA Ato &amp; Vallejo (2015) proponen utilizar el test de Durbin-Watson para comprobar la independencia de los residuales del modelo.↩︎ "]]
