[["introducción-a-los-procedimientos-de-investigación-en-psicología.html", "1 Introducción a los procedimientos de investigación en Psicología", " 1 Introducción a los procedimientos de investigación en Psicología El objetivo de toda investigación psicológica es la obtención de conocimiento válido. Para ello, es necesario que ese conocimiento se haya obtenido mediante un procedimiento sistemático que llamamos método científico. Precisamente, el origen de la Psicología como ciencia se encuentra en la utilización de un método diferente al filosófico para el estudio de la vida mental (Anguera et al., 1995). Aunque hay ocasiones en las que se ha señalado la existencia de distintos métodos de investigación en Psicología, conviene aclarar que compartimos la opinión de que la lógica de la investigación científica configura un único método de investigación, existiendo varias estrategias o procedimientos para alcanzar estos objetivos. Son varios los criterios utilizados para clasificar las distintas estrategias de investigación.(Anguera et al., 1995). Uno de los más relevantes es la existencia de manipulación o no de la variable independiente (VI). Mediante este criterio distinguimos entre los estudios manipulativos y los nos manipulativos. Dentro de los manipulativos incluimos los diseños experimentales y los cuasiexperimentales. Entre los no manipulativos distinguimos entre los selectivos (Ato &amp; Vallejo (2015) los denomina asociativos) y los observacionales. En este tema vamos a estudiar algunos diseños de investigación así como las técnicas estadísticas asociadas a los mismos. Realizaremos una clasificación de los diseños de investigación y posteriormente pasaremos a estudiar los conceptos básicos relacionados con la inferencia estadística. "],["lógica-de-la-investigación-científica.html", "1.1 Lógica de la investigación científica", " 1.1 Lógica de la investigación científica La investigación científica intenta resolver problemas mediante un procedimiento que parte de la formulación de una serie de hipótesis. Con objeto de contrastar dichas hipótesis, el investigador diseña un estudio en el que recogerá información que le permitirá tomar decisiones acerca de la validez de sus hipótesis. La generación de problemas de la investigación científica no obedece a ninguna estrategia sistemática, sino que en muchos casos es el resultado de la casualidad o el azar. Sin embargo, generar problemas relevantes mejora cuando se dispone de un profundo conocimiento de la temática sobre la que se investiga. Aunque la inspiración no tiene reglas, resulta conveniente que se posea un buen conocimiento del campo de investigación con el que se podrá evaluar la idoneidad y relevancia del mismo. El diseño de investigación si tiene una sistemática bien consolidada. Consiste en un plan estructurado de acción que pretende realizar las acciones comparativas en condiciones de validez. Aunque existen muchos criterios de clasificación (estrategia, número de variables, grado de intervención, etc.), aquí vamos a centrarnos en el que consideramos más relevante y que se relaciona con el tipo de estrategia seguida por el investigador para realizar las acciones comparativas (medir la covariación o concomitancia entre dos fenómenos) en base a los objetivos de investigación. Se distinguen dos estrategias: Transversal: Utiliza grupos diferentes para estudiar cada uno de los valores de la variable independiente. Supongamos que queremos conocer qué procedimiento es el mejor para conseguir reducir peso. Tenemos cuatro tratamientos (sin tratamiento, dieta, fármacos y dieta + ejercicio). Seleccionamos una muestra de individuos y asignamos aleatoriamente cada uno de ellos a uno de los tratamientos. A cada individuo se le pesa antes de comenzar el tratamiento y después de recibir el tratamiento. Comparamos la diferencia de peso en cada una de las cuatro condiciones. Longitudinal: Utiliza un único grupo que recibe todos los valores de la variable independiente en momentos distintos. Supongamos que queremos estudiar cómo influye el paso del tiempo en el recuerdo. Para ello, se le pide a los individuos que lean una historia durante 15 minutos. Pasada una hora se le pide que escriban todo lo que recuerdan. Asimismo, se le vuelve a pedir que escriban todo lo que recuerdan al cabo de un día, al cabo de una semana y al cabo de un mes. Por lo general, estas dos estrategias suelen aparecer conjuntamente en muchos diseños de investigación. "],["validez-de-las-investigaciones.html", "1.2 Validez de las investigaciones", " 1.2 Validez de las investigaciones La validez de un estudio depende la naturaleza de las variables y sus definiciones, del diseño de investigación y de la técnica estadística utilizada. 1.2.1 Validez de las variables y definiciones En toda investigación científica se trabaja con conceptos que deben ser operacionalizados para que puedan ser medidos y presenten un significado unívoco. Los problemas de validez surgen cuando las operaciones realizadas no tienen nada que ver con el constructo estudiado o su vinculación es parcial. Las variables pueden medirse mediante cuatro escalas de medida (nominal, ordinal, intervalo y razón). La elección del tipo de medida determinará el tipo de análisis de los datos. Hay ocasiones en las que se han utilizado los términos de cualitativo y cuantitativo para clasificar los distintos tipos de variables (Ato &amp; Vallejo, 2007). Dentro de las variables cualitativas suelen diferenciarse las variables en función de que su escala de medida sea nominal u ordinal. Las variables cuantitativas se distinguen en función de su dominio sea discreto o continuo. Otra clasificación frecuente en Psicología es la distinción entre variable independiente (VI) o variable predictora (VP), variable dependiente (VD) y variables extrañas (VE). En ocasiones se habla de variable criterio en los contextos en los que no hay manipulación en el diseño de investigación. En estos estudios a la VD también se le denomina variable de respuesta (VR) y la VI como variable predictora. 1.2.2 Validez del diseño de investigación Con el diseño tenemos que asegurarnos de que las variables extrañas están debidamente controladas (validez interna). Para ello, resulta conveniente utilizar técnicas de control tales como la manipulación de la VI, la aleatorización, el mantenimiento constante de dichas variables o el control estadístico. Asimismo, es importante considerar la generalización los resultados del estudio a otras situaciones. En este caso, estamos hablando de validez externa. 1.2.3 Validez de conclusión estadística La elección de la técnica estadística también influye en la validez de la investigación. Una técnica mal seleccionada puede llevarnos a sacar conclusiones inadecuadas. Afecta a la determinación de la existencia de covariación entre las variables y a su grado. El procedimiento para obtener conclusiones estadísticas es el contraste de hipótesis. Este procedimiento consiste en la toma de decisiones sobre dos hipótesis rivales y excluyentes en base a la probabilidad calculada de un estadístico. Más adelante se desarrollará este concepto para su completa comprensión. Entre los errores que se cometen mediante la contrastación de hipótesis es el considerar que existe relación cuando no existe (error tipo I o riesgo \\(\\alpha\\)), o considerar que no existe relación cuando la hay (error tipo II o riesgo \\(\\beta\\)). Otro error posible es la sobre-estimación o infraestimación de la relación. Posibles factores que pueden afectar a la conclusión estadística es la baja potencia y la violación de los supuestos. También es importante considerar la magnitud del efecto y la significación práctica y clínica de los resultados. 1.2.4 Contraste de hipótesis estadísticas Dentro de la inferencia estadística buscamos realizar comparaciones y establecer relaciones mediante la estimación de parámetros y el contraste de hipótesis. El primer procedimiento puede hacerse mediante la estimación puntual o por intervalos. En cambio, el contraste de hipótesis es la toma de decisiones acerca de si un conjunto de datos corrobora una hipótesis. Supone cubrir una serie de etapas: 1) Formulación de las hipótesis: Se plantean la hipótesis nula (\\(H_0\\)) que considera que las variaciones existentes entre las condiciones se debe al azar y la hipótesis alternativa (\\(H_1\\)) que niega la hipótesis nula y considera que las variaciones en una variable están relacionada con los cambios en la otra. Las hipótesis pueden ser bidireccionales (no conocemos el sentido de la relación como por ejemplo \\(\\mu_1 = \\mu_2\\)) o unilaterales (el investigador plantea donde se encontrarán las diferencias como por ejemplo \\(\\mu_1 \\leq \\mu_2\\) ). 2) Definición del estadístico de contraste: Su cálculo supone la realización de un estudio empírico en el que se ha extraído una muestra aleatoria de la población. Este estadístico debe tener una distribución de probabilidad conocida. 3) Regla de decisión: Se basa en la compatibilidad que existe entre la hipótesis nula y los datos empíricos (Pardo &amp; SanMartin, 2010). Permite determinar la probabilidad de que \\(H_0\\) sea cierta en base a nuestros resultados. Para determinar el grado de apoyo de \\(H_0\\) se divide a la distribución teórica en dos regiones (región de confianza y región crítica). La región de confianza es la zona de la distribución teórica en la que se acepta \\(H_0\\). Existe consenso en considerar que esta región alcance el 95% de probabilidad. La región crítica es la zona complementaria a la región de confianza (por lo que cubre el 5% de la distribución) y si el estadístico pertenece a esa zona se rechaza \\(H_0\\). Si la hipótesis es bilateral la región crítica estará a ambos lados de la distribución teórica. En cambio, si la hipótesis es unilateral la región de confianza estará situada en una de las colas de las distribución. Ejemplo 1: A continuación, se presentan los resultados de un estudio en el que se quiso comparar el aprendizaje de los niños dependiendo del tipo de método (fonético versus global). Cada niño sólo fue entrenado con un único método y se quería conocer si había diferencias significativas entre ambos métodos. Nos estamos planteando una hipótesis bidireccional: Tabla 1.1: Datos del ejemplo 1 Fonetico 6 6 3 4 2 5 7 Global 4 5 6 7 8 4 8 \\(H_0\\): No hay diferencias en el aprendizaje (\\(\\mu_{F} = \\mu_G\\)) \\(H_1\\): El aprendizaje es mejor con el método global (\\(\\mu_{F} \\neq \\mu_G\\)) Para contrastar esta hipótesis necesitamos un estadístico con distribución de probabilidad conocida. En este caso, es el estadístico t de Student: \\[ \\bar{Y}_{\\bar{Y}_{1} - \\bar{Y}_{2}}= \\bar{Y}_{1} - \\bar{Y}_{2} \\] \\[ Var(\\bar{Y}_{1} - \\bar{Y}_{2}) = \\sigma_{1}^{2}/n_{1} + \\sigma_{2}^{2}/n_{2} \\] \\[ t = \\frac{\\bar{Y}_{\\bar{Y}_{1} - \\bar{Y}_{2}}}{Var(\\bar{Y}_{1} - \\bar{Y}_{2})} \\sim t(n-2) \\] En nuestro caso, el valor del estadístico t vale: ## ## Two Sample t-test ## ## data: rendimiento by metodo ## t = -2.5955, df = 12, p-value = 0.02342 ## alternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0 ## 95 percent confidence interval: ## -4.2044435 -0.3669851 ## sample estimates: ## mean in group 1 mean in group 2 ## 4.142857 6.428571 Encontramos que el valor de estadístico t vale -2.596 y su valor de probabilidad es 0.023. En base a estos resultados podemos rechazar \\(H_0\\). Esto significa que el estadístico t se aleja bastante de la predicción establecida mediante la hipótesis nula. Es decir, existe muy poca compatibilidad entre nuestros datos y \\(H_0\\). Para aceptar estos resultados debemos confirmar que se cumplen los supuestos de la prueba (normalidad de las muestras y homogeneidad de las varianzas 1): ## ## Shapiro-Wilk normality test ## ## data: rendimiento[1:7] ## W = 0.92025, p-value = 0.4713 ## ## Shapiro-Wilk normality test ## ## data: rendimiento[8:14] ## W = 0.91511, p-value = 0.4324 ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 1 0.06 0.8106 ## 12 Ejemplo 2: A continuación, se presentan los resultados de un estudio en el que se quiso comparar el aprendizaje de los niños dependiendo del tipo de método (fonético versus global). Cada niño sólo fue entrenado con un único método y se esperaba encontrar un mayor rendimiento con el método global. Aquí nos planteamos una hipótesis unidireccional: Tabla 1.1: Datos del ejemplo 1 Fonetico 6 6 3 4 2 5 7 Global 4 5 6 7 8 4 8 \\(H_0\\): No hay diferencias en el aprendizaje (\\(\\mu_{F} \\geq \\mu_G\\)) \\(H_1\\): El aprendizaje es mejor con el método global (\\(\\mu_{F} &lt; \\mu_G\\)) Para contrastar esta hipótesis necesitamos un estadístico con distribución de probabilidad conocida. En este caso, es el estadístico es el mismo y tiene el mismo valor. Sólo cambia su probabilidad: ## ## Two Sample t-test ## ## data: rendimiento by metodo ## t = -2.5955, df = 12, p-value = 0.01171 ## alternative hypothesis: true difference in means between group 1 and group 2 is less than 0 ## 95 percent confidence interval: ## -Inf -0.7161774 ## sample estimates: ## mean in group 1 mean in group 2 ## 4.142857 6.428571 Ejemplo 2: A continuación, se presentan los resultados de un estudio en el que se quiso comparar el aprendizaje de los niños dependiendo del tipo de método (fonético versus global). Cada niño sólo fue entrenado con un único método y se esperaba encontrar un mayor rendimiento con el método global. Aquí nos planteamos una hipótesis unidireccional: Tabla 1.1: Datos del ejemplo 1 Fonetico 6 6 3 4 2 5 7 Global 4 5 6 7 8 4 8 \\(H_0\\): No hay diferencias en el aprendizaje (\\(\\mu_{F} \\geq \\mu_G\\)) \\(H_1\\): El aprendizaje es mejor con el método global (\\(\\mu_{F} &lt; \\mu_G\\)) Para contrastar esta hipótesis necesitamos un estadístico con distribución de probabilidad conocida. En este caso, es el estadístico es el mismo y tiene el mismo valor. Sólo cambia su probabilidad: ## ## Two Sample t-test ## ## data: rendimiento by metodo ## t = -2.5955, df = 12, p-value = 0.01171 ## alternative hypothesis: true difference in means between group 1 and group 2 is less than 0 ## 95 percent confidence interval: ## -Inf -0.7161774 ## sample estimates: ## mean in group 1 mean in group 2 ## 4.142857 6.428571 Encontramos que el valor de estadístico t vale en este caso t vale -2.596 y su valor de probabilidad es 0.012. Ejemplo 3: Con los mismos datos del ejemplo anterior supongamos que el investigador está interesado en conocer si la media del rendimiento en la población de los estudiantes es 6. Para ello formula las siguientes hipótesis: \\(H_0\\): \\(\\mu_{rendimiento}\\) = 6 \\(H_1\\): \\(\\mu_{rendimiento} \\neq\\) 6 Como no conocemos el sentido de la dirección asumimos que la hipótesis es bilateral. Para contrastar esta hipótesis necesitamos conocer si la distribución de la variable sigue una ley normal. En caso de que se cumpla esta hipótesis realizaremos el contraste con la prueba t para una muestra. Si no se cumple, usaremos la prueba de Wilcoxon para una muestra. En este caso, se cumple la normalidad de la variable por lo usamos la prueba t. shapiro.test(rendimiento) ## ## Shapiro-Wilk normality test ## ## data: rendimiento ## W = 0.92677, p-value = 0.2747 t.test(rendimiento) ## ## One Sample t-test ## ## data: rendimiento ## t = 9.9992, df = 13, p-value = 1.801e-07 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## 4.143709 6.427720 ## sample estimates: ## mean of x ## 5.285714 Rechazamos la hipótesis de que el valor medio de la variable rendimiento es 6 en la población. Ejemplo 4: Supongamos que construimos un examen para evaluar los conocimientos de los estudiantes de Psicología en la materia de Diseño y Análisis de Datos II. El examen tendrá 10 preguntas con 3 opciones de respuesta y solo una correcta. Queremos conocer cuántas preguntas debe responder correctamente el alumno para estar seguros de que sabe y de que no ha respondido por azar. Las hipótesis en este contraste estadístico serán: \\(H_0\\): El alumno no sabe por lo que responde al azar (\\(\\pi_{acierto} \\leq\\) 0.333) \\(H_1\\): El alumno sabe. No responde al azar (\\(\\pi_{acierto} &gt;\\) 0.333) Ahora necesitamos determinar cuántas preguntas suponen responder por azar. Está claro si el alumno acierta sólo 1 pregunta la probabilidad de que haya respondido por azar 0 ó 1 es muy alta. En la siguiente figura se aprecia que los valores más probables están comprendidos entre 2 y 4: Figura 1.1: Distribución binomial # Probabilidad igual a 2: dbinom(2,10,1/3) ## [1] 0.1950922 # Probabilidad igual a 3: dbinom(3,10,1/3) ## [1] 0.2601229 # Probabilidad igual a 4: dbinom(4,10,1/3) ## [1] 0.2276076 Por tanto, necesitamos encontrar el número de preguntas acertadas que tengan una probabilidad de ser acertadas por azar \\(\\leq\\) 0,05. Esto se consigue con 6 preguntas acertadas. Con 5 preguntas acertadas estaríamos por encima del nivel de riesgo establecido por convención del 5%: # Probabilidad menor o igual a 6: pbinom(6,10,1/3) [1] 0.9803384 # Probabilidad de la región crítica con 6 preguntas: 1 - pbinom(6,10,1/3) [1] 0.01966164 # Probabilidad de la región crítica con 5 preguntas: 1 - pbinom(5,10,1/3) [1] 0.07656353 No obstante, el criterio de 0,05 es un criterio establecido arbitrariamente y que supone la ausencia de factores contaminantes que estarían actuando en la situación real de examen y que podrían afectar al resultado del examen. Un profesor algo más exigente podría considerar la necesidad de aprobar acertando 7 preguntas. En este caso, la probabilidad de que un estudiante acertara por azar sería: # Probabilidad menor o igual a 7: pbinom(7,10,1/3) [1] 0.996596 # Probabilidad de la región crítica con 7 preguntas: 1 - pbinom(7,10,1/3) [1] 0.003403953 En este caso no es necesario calcular la normalidad de los errores, ya que si las muestras son normales también serán normales los errores. Esto se verá con más claridad en el próximo tema.↩︎ "],["potencia-de-un-contraste.html", "1.3 Potencia de un contraste", " 1.3 Potencia de un contraste Dado que él área de una distribución teórica vale 1 sabemos que 1 - \\(\\alpha\\) es la probabilidad asociada a la región de confianza. O lo que es lo mismo, la probabilidad de aceptar \\(H_0\\) cuando es cierta. Del mismo modo, 1 - \\(\\beta\\) es la probabilidad de rechazar \\(H_0\\) cuando es falsa. A esta probabilidad se le llama potencia de la prueba. Figura 1.2: Errores en la inferencia estadística Pardo &amp; SanMartin (2010) consideran que la potencia de un contraste hace referencia “a la sensibilidad del contraste para detectar como falsa una hipótesis nula que realmente lo es. Cuanto mayor es la potencia, mayor es la de que una hipótesis nula falsa sea reconocida como tal. Si la potencia es baja, también será baja la probabilidad de detectar un efecto.” La potencia de la prueba depende del nivel de riesgo \\(\\alpha\\), del error típico de la distribución teórica y del valor real de \\(H_1\\). Puede aumentarse modificando cualquiera de los tres factores mencionados, pero una forma sencilla de aumentarla es incrementando el tamaño de la muestra. Asimismo, mejorar el diseño del estudio o utilizar medidas con mayor fiabilidad y validez también son estrategias posibles para mejorar la potencia estadística del contraste. "],["tamaño-del-efecto.html", "1.4 Tamaño del efecto", " 1.4 Tamaño del efecto Hemos visto anteriormente que para determinar la potencia de la prueba un elemento necesario es fijar el valor real de \\(H_1\\). Como este valor no se conoce a priori debemos determinarlo. Pues bien, la distancia del valor del estadístico entre \\(H_0\\) y el valor real de \\(H_1\\) es lo que se denomina tamaño del efecto. Cuando se realizan comparaciones entre variables el tamaño del efecto hace referencia a la magnitud de la diferencia, mientras que cuando se estudian relaciones el tamaño del efecto se refiere a la intensidad de la relación. Dado que la potencia de un contraste depende del tamaño muestral podemos encontrar diferencias de medias muy pequeñas que sean significativas. Bastará con tener un tamaño de muestra suficientemente grande. Por tanto, la significación estadística permite contrastar hipótesis, pero no es un buen indicador de la relevancia de la relación. Existen una gran variedad de medidas del tamaño del efecto. Pardo &amp; SanMartin (2010) consideran que todas ellas pueden clasificarse en dos grandes tipos: 1) basadas en las estandarización de la diferencia entre las medias y 2) las basadas en la proporción de varianza explicada. En los siguientes temas se estudiarán algunos de ellos. "],["contrastes-de-hipótesis-en-los-programas-estadísticos.html", "1.5 Contrastes de hipótesis en los programas estadísticos", " 1.5 Contrastes de hipótesis en los programas estadísticos 1.5.1 Contrastes para 1 variable El árbol de decisión para estos contrastes es el siguiente: Figura 1.3: Contrastes para 1 variable 1.5.1.1 Prueba t para 1 muestra mediante el programa JAMOVI Se selecciona el módulo de “Pruebas T” y marcamos la opción ”Prueba T para una muestra”. En la ventana de la prueba T para una muestra aparece por defecto marcada la prueba T y marcando la opción de “Comprobación de supuestos” puede obtenerse el resultado de la prueba de normalidad. Para realizar el análisis es necesario indicar el valor de prueba en la sección de “Hipótesis” (en nuestro ejemplo se ha introducido el valor de 47). Por defecto, aparece marcada la opción del contraste bilateral aunque existen opciones para los contrastes unilaterales. Asimismo, tendríamos que marcar la opción de “Rangos de Wilcoxon” en el caso de que no se acepte la hipótesis de normalidad. Figura 1.4: Prueba t para una muestra en JAMOVI Figura 1.5: Prueba t para una muestra en JAMOVI 1.5.1.2 Prueba t para 1 muestra en el programa SPSS Vamos a presentar la forma de realizar algunos contrastes estadísticos que se utilizarán en esta asignatura a modo de recordatorio, ya que fueron estudiados en otras asignaturas. 1.5.1.2.1 Prueba de normalidad de Shapiro-Wilk Para determinar la normalidad será necesario aplicar la prueba de Shapiro-Wilk.En el programa SPSS se hace marcando Analizar + Explorar + Gráficos + Gráficos con pruebas de normalidad. Los resultados obtenidos pueden observarse en las siguientes imágenes. Figura 1.6: Prueba de normalidad Shapiro-Wilks en el programa SPSS Figura 1.7: Prueba de normalidad en SPSS Figura 1.8: Prueba de normalidad en SPSS Figura 1.9: Resultados de la prueba de normalidad La prueba t para 1 muestra se realiza marcando Analizar + Comparar medias + Prueba T para una muestra: Figura 1.10: Prueba t para una muestra en el programa SPSS Figura 1.11: Prueba t para una muestra en el programa SPSS será necesario introducir la VD a estudiar en el cuadro de “Variable a contrastar”. El valor del contraste es cero por defecto, pero habrá que introducir el valor de la hipótesis a contrastar. 1.5.1.2.2 Prueba de Wilcoxon para una muestra Necesitamos marcar Analizar + Pruebas no paramétricas + Cuadro de diálogos antiguos + 2 muestras relacionadas. Observamos que el programa SPSS nos pide introducir dos variables, ya que esta prueba está diseñada para estudiar la relación entre dos variables. Sin embargo, puede utilizarse introduciendo la variable en cuestión y como segunda variable una nueva que hemos creado con el valor de contraste de nuestras hipótesis (en la figura aparece con el nombre de Mdn): Figura 1.12: Prueba de Wilcoxon en el SPSS Figura 1.13: Prueba de Wilcoxon en el SPSS 1.5.2 Contrastes para 1 VI cualitativa y una VD cuantitativa El árbol de decisión para los diseños en los que solo hay 1 medida por sujeto (muestras independientes) es: Figura 1.14: Técnicas para dos muestras independientes 1.5.2.1 Prueba t para muestras independientes en JAMOVI Se selecciona la opción de muestras independientes en el modulo de “Pruebas T”. Se introduce la variable dependiente (cuantitativa) en el cuadro de “Variables dependientes y la variable cualitativa en el cuadro de “Variable de agrupación”. Se seleccionan las opciones para comprobar los supuestos de la prueba y se elige la prueba (T de student, T de Welch o U de Mann-Whitney), dependiendo de los supuestos que se cumplan. Figura 1.15: Prueba t para muestras independientes en JAMOVI 1.5.2.2 Prueba t para muestras independientes en SPSS Se realiza marcando Analizar + Comparar medias + Prueba T para muestras independientes: Figura 1.16: Prueba t para muestras independientes en SPSS Figura 1.17: Prueba t para muestras independientes en SPSS 1.5.2.3 Prueba U de Mann-Whitney para muestras independientes en SPSS Se obtiene marcando Analizar + Pruebas no paramétricas + Cuadro de diálogos antiguos + 2 muestras independientes. Figura 1.18: Prueba U para muestras independientes en SPSS Figura 1.19: Prueba U para muestras independientes en SPSS 1.5.3 Pruebas para muestras relacionadas (2 medidas por unidad de observación) El árbol de decisión para este apartado es el siguiente: Figura 1.20: Pruebas para dos muestras relacionadas La variable sobre la que se realiza el contraste es la diferencia entre las medidas de los dos momentos. Por tanto, el análisis de estos diseños se convierte en el análisis sobre 1 muestra que ya se ha estudiado anteriormente. 1.5.3.1 Prueba t para muestras relacionadas en el programa JAMOVI Se selecciona la opción de “Muestras Apareadas” en el modulo de “Pruebas T”. Se introduce las dos variables dependientes (cuantitativas) en el cuadro de *“Variables Apareadas”. Se selecciona la opción para “Comprobación de supuestos” de la prueba y se elige la prueba (T de student o W de Wilcoxon), dependiendo de que se cumpla el supuesto de normalidad. Estos resultados son los mismos que si se hubieran calculado la diferencia entre las dos medidas y se hubiera aplicado la prueba T para una muestra. Figura 1.21: Prueba t para muestras relacionadas en JAMOVI 1.5.3.2 Prueba t para muestras relacionadas en el programa SPSS Se realiza marcando Analizar + Comparar medias + Prueba T para muestras relacionadas: Figura 1.22: Prueba t para muestras relacionadas en SPSS Figura 1.23: Prueba t para muestras relacionadas en SPSS 1.5.3.2.1 Prueba de Wilcoxon para 2 muestras relacionadas Necesitamos marcar Analizar + Pruebas no paramétricas + Cuadro de diálogos antiguos + 2 muestras relacionadas. Figura 1.24: Prueba de Wilcoxon para muestras relacionadas en SPSS Figura 1.25: Prueba de Wilcoxon para muestras relacionadas en SPSS "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
